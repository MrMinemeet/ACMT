% !TEX root = ../Vorlage_DA.tex
%	########################################################
% 							Vorwort
%	########################################################


%	--------------------------------------------------------
% 	Überschrift, Inhaltsverzeichnis
%	--------------------------------------------------------
\chapter*{Abstract}
% ENGLISH
A self driving car has to orientate in the immediate vicinity. For this purpose the car needs a map and the own position in the map. Why is this such an important task when we already have technology like Global Positioning System (\gls{gps})? \gls{gps} provides routing data, but no live details what happens on the street, like an ongoing construction or a pedestrian crossing the street. To get this information the car has to collect visual data from its environment in real-time. This thesis examines two approaches of visual data processing to generate a map and locate the car inside this map. One approach is the Simultaneous Localization And Mapping (\gls{slam}, the other one uses artificial intelligence. The platform for ORB-\gls{slam} and LSD-\gls{slam} is the Robot Operating System (\gls{ros}), which handles the publish/subscriber based communication between the camera and the \gls{slam} algorithms. The third method DeepTAM uses Deep Neural Networks which can learn to predict the distance between objects in a image when given enough training data. It is a system for keyframe-based dense camera tracking and depth map estimation that is entirely learned. This thesis shows how to implement the different algorithms in \gls{ros} and points out the pros and cons of each method compared to the others and gives an outlook into future methods.
\newline
\newline
\newline
\newline
% GERMAN
Ein großes Problem für selbstfahrende Autos ist es, die Umgebung, in der sich das Auto befindet, zu analysieren und die eingehenden Daten zu verarbeiten, um das Maximum an Informationen herauszuholen.  Warum ist dies eine so wichtige Aufgabe, wenn wir bereits über Technologie wie \gls{gps} verfügen? Weil \gls{gps} nicht immer so genau oder gar nicht verfügbar ist und die Informationen immer auf dem neuesten Stand sein müssen (z.B. Änderungen aufgrund einer Baustelle). Diese Arbeit konzentriert sich auf das Problme, wenn die Eingangsdaten von einer Kamera geholt weden und somit nur visuelle Daten enthalten. Es wurden drei verschiedene Methoden getestet. Alle haben gemeinsam, das sie die Daten zur Erstellung einer digitalen Karte verwenden und die Position des Fahrzeugs selbst in dieser Karte anzeigen. Die ersten beiden Methoden ORB-SLAM und LSD-SLAM sind mathematische Algorithmen. Beide arbeiten mit dem für den praktischen Einsatz wichtigen Robot Operating System (ROS). Die dritte Methode DeepTAM verwendet ein sogenanntes Deep Neural Network, welches aus genug Trainingsdaten lernen kann. Es handelt es sich um ein Keyframe basiertes System von Kameraverfolgung und Tiefenschätzung zur Generierung von 3D Karten. Diese Arbeit vergleicht und zeigt die Vor- und Nachteile der einzelnen Methoden. Außerdem gibt sie einen Blick in zukünftige Angehensweisen.
 

\addcontentsline{toc}{chapter}{Abstract}