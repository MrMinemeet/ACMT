% Discription of what ORB-SLAM is, how it works and implementation

\chapter{ORB-SLAM2\authorA}\label{ref:orbslam}

\section{What is ORB-SLAM?}
ORB-SLAM2 is a versatile, real-time \gls{slam} implementation which uses Mono-, Stereo- and \gls{rgbd} cameras. It's designed to generate a 3D map from prominent points in the picture and keypoints. It features loop closing, re-localization and a reusable map \cite{orbslam2}. It works in a wide variety of use cases. The image that the \gls{slam} uses can be gathered from small hand-held cameras, cameras on drones for top-down mapping and cameras on cars for self driving.
ORB-SLAM2 is based on ORB-SLAM and was inter alia developed by Ra√∫l Mur-Artal who already worked on ORB-SLAM.\newline
\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\textwidth]{./media/images/orb-slam-kitti-dataset.png}
  	\caption{ORB-SLAM Example image
  	\\Src: \url{https://tinyurl.com/ruvnj39}}
  	\label{orbslamkittidataset}
\end{figure}

\section{How does the ORB-SLAM work?}

The \gls{slam} is made out of multiple blocks which all handle a different type of operation. These operations range from extracting the keypoints to localization.

\subsection{Extracting Keypoints}
The \gls{slam} uses a feature-based method. This means that it extracts features on prominent keypoints throughout the image input. These feature information is then distributed to all operations which handle them independently from the camera type \cite{orbslam2}.  \newpage


This is how finding these keypoints works on different camera types:
\begin{itemize}
    \item \underline{Stereo Image} \newline
    For a stereo camera setup the keypoints get extracted from the image using a survival of the fittest process, were the most prominent points stay until a threshold is reached. This is done for both images separately and then the left keypoints are searched on the right image. Then the found points get compared to the original ones that where found on the right side
    \item \underline{RGB-D Image} \newline
    On a \gls{rgbd} camera keypoints get extracted using prominent keypoints and then calculating the approximate position using the depth information of from the depth sensor.
    \item \underline{Monocular Image} \newline
    On a Monocular image the approximate position gets triangulated by using multiple images. The disadvantage is that they don't provide a scale information and only do rotational and transnational movement estimations.
\end{itemize}

\subsection{Loop-closing and Bundle Adjustments}
Loop-closing and bundle adjustments are performed in two steps. First the loop-closing will happen when the system detects overlapping environments where the system changes scaling to reconnect certain parts as scale drifting will occur on monocular cameras.\newline
Second step is the bundle adjustment, which gets executed after a successful loop-closing, where the system tries to optimize all keypoints and keyframes using the Levenberg-Marquardt method (alternative to Gauss-Newton method) \cite{LevenbergMarquardMethod}. Figure \ref{img:loopclosing} shows the optimization process. It tries to adjust the map in a way it makes sense again.  Also the camera orientation and position will be optimized to compensate errors in tracking. All the bundle adjustment is done in a separate thread since this is a more computational task.\newline
When finished, the updated and optimized keyframes and keypoints get merged into the original keyframes and keypoints \cite{orbslam2}.\newline
\begin{figure}[h!]
	\centering
	\includegraphics[width=0.8\textwidth]{./media/images/loopclosing.PNG}
  	\caption{Loop-Closing example
  	\\Src: \url{https://tinyurl.com/to4678g}}
  	\label{img:loopclosing}
\end{figure}

\subsection {Localization}
When an area has been mapped well in the past the \textit{Localization Mode} can be turned on which deactivates the Local Mapping and the Loop Closing thread.
Locating is done by continuously comparing the previous points with the current points of the image. This works when an area is unmapped but drifting might add up.
Matching the current points with the one on the map will ensure that it is drift-free \cite{orbslam2}. There are a few points that are pretty important to keep in mind to achieve good results. The points can be viewed in section \ref{ref:orbslamgetgoodresults}.

\subsection{Input/Output}
\textbf{Input Data:} rectified Monochrome/Color images\newline
\textbf{Output Data:} Rough 3D map with pixel-points and image with current prominent keypoints